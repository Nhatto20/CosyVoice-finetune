{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ecd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7296b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('third_party/Matcha-TTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cb61db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\japan\\\\CosyVoice'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f9a39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to import ttsfrd, use wetext instead\n"
     ]
    }
   ],
   "source": [
    "from cosyvoice.cli.cosyvoice import CosyVoice2\n",
    "from cosyvoice.utils.file_utils import load_wav\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc534b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\lightning\\fabric\\__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\diffusers\\models\\lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "2025-11-19 20:37:44,301 INFO input frame rate=25\n",
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "2025-11-19 20:37:58,020 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: C:\\Users\\japan\\.cache\\modelscope\\hub\\pengzhendong/wetext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 20:38:02,345 DEBUG https://www.modelscope.cn:443 \"GET /api/v1/models/pengzhendong/wetext/revisions HTTP/1.1\" 200 222\n",
      "2025-11-19 20:38:03,203 DEBUG https://www.modelscope.cn:443 \"GET /api/v1/models/pengzhendong/wetext/repo/files?Revision=master&Recursive=True HTTP/1.1\" 200 None\n",
      "2025-11-19 20:38:04,138 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: C:\\Users\\japan\\.cache\\modelscope\\hub\\pengzhendong/wetext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 20:38:07,647 DEBUG https://www.modelscope.cn:443 \"GET /api/v1/models/pengzhendong/wetext/revisions HTTP/1.1\" 200 222\n",
      "2025-11-19 20:38:08,091 DEBUG https://www.modelscope.cn:443 \"GET /api/v1/models/pengzhendong/wetext/repo/files?Revision=master&Recursive=True HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "cosyvoice = CosyVoice2(r\"C:\\Users\\japan\\datasets\\pretrained_models\\CosyVoice2-0.5B-original\", load_jit=False, load_trt=False, load_vllm=False, fp16=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c0990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosyvoice_old = CosyVoice2(r\"C:\\Users\\japan\\datasets\\pretrained_models\\CosyVoice2-0.5B-original\", load_jit=False, load_trt=False, load_vllm=False, fp16=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06390ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-11-19 20:38:59,683 INFO synthesis text tự nhiên thấy mình thật là đẹp troai.\n",
      "c:\\Users\\japan\\miniconda3\\envs\\cosyvoice\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:54: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "2025-11-19 20:39:47,513 INFO yield speech len 8.8, rtf 5.435220138593153\n",
      "100%|██████████| 1/1 [00:51<00:00, 51.97s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_speech_16k = load_wav(r\"C:\\Users\\japan\\Workspaces\\AI\\NLP\\Speech\\ref.wav\", 16000)\n",
    "for i, j in enumerate(cosyvoice.inference_zero_shot('tự nhiên thấy mình thật là đẹp troai', 'cả hai bên hãy cố gắng hiểu cho nhau', prompt_speech_16k, stream=False)):\n",
    "    torchaudio.save('zero_shot_new.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed73a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_speech_16k = load_wav(r'C:\\Users\\japan\\Workspace\\AI_Engineer\\Speech\\ref.wav', 16000)\n",
    "# for i, j in enumerate(cosyvoice_old.inference_zero_shot('tự nhiên thấy mình thật là đẹp troai', 'cả hai bên hãy cố gắng hiểu cho nhau', prompt_speech_16k, stream=False)):\n",
    "#     torchaudio.save('zero_shot_old.wav'.format(i), j['tts_speech'], cosyvoice_old.sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_speech_16k = load_wav(audio_path, 16000)\n",
    "# for i, j in enumerate(cosyvoice.inference_zero_shot(speech_script, prompt_script, prompt_speech_16k, stream=False)):\n",
    "#     torchaudio.save(generated_file_name.format(i), j['tts_speech'], cosyvoice.sample_rate)\n",
    "\n",
    "\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def generate_from_real_folder(\n",
    "    real_folder: str,\n",
    "    generated_folder: str,\n",
    "    cosyvoice,\n",
    "    sr: int = 16000\n",
    "):\n",
    "    \"\"\"\n",
    "    real_folder: path chứa .txt và .normalized.wav\n",
    "    generated_folder: nơi lưu file speech sinh ra\n",
    "    cosyvoice: model inference đã load sẵn\n",
    "    sr: sample rate để load prompt speech\n",
    "    \"\"\"\n",
    "    os.makedirs(generated_folder, exist_ok=True)\n",
    "\n",
    "    # Thu thập các file txt\n",
    "    real_files = [f for f in os.listdir(real_folder) if f.endswith(\".wav\")]\n",
    "\n",
    "    print(f\"Found {len(real_files)} real samples.\")\n",
    "\n",
    "    for wav_file in real_files[:400]:\n",
    "        base_name = wav_file.replace(\".wav\", \"\")\n",
    "        wav_path = os.path.join(real_folder, wav_file)\n",
    "        txt_path = os.path.join(real_folder, base_name + \".txt\")\n",
    "\n",
    "        # Kiểm tra file .wav có tồn tại\n",
    "        if not os.path.exists(wav_path):\n",
    "            print(f\"[WARN] Missing wav for {base_name}. Skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Đọc script\n",
    "        with open(txt_path, \"r\", encoding=\"utf8\") as f:\n",
    "            speech_script = f.read().strip()\n",
    "            prompt_script = speech_script  # có thể thay bằng prompt khác\n",
    "\n",
    "        # Load prompt speech\n",
    "        prompt_speech = load_wav(wav_path, sr)\n",
    "\n",
    "        # Output filename\n",
    "        out_path = os.path.join(generated_folder, base_name + \".wav\")\n",
    "\n",
    "        print(f\"[Generating] {base_name} → {out_path}\")\n",
    "\n",
    "        # Tiến hành inference\n",
    "        outputs = cosyvoice.inference_zero_shot(\n",
    "            prompt_script,\n",
    "            speech_script,\n",
    "            prompt_speech,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # Model có thể trả nhiều chunk → chỉ lưu chunk cuối hoặc ghép lại\n",
    "        all_audio = []\n",
    "        for out in outputs:\n",
    "            all_audio.append(out[\"tts_speech\"])\n",
    "\n",
    "        # Ghép lại toàn bộ\n",
    "        generated_audio = torch.cat(all_audio, dim=-1)\n",
    "\n",
    "        # Lưu file\n",
    "        torchaudio.save(out_path, generated_audio, cosyvoice.sample_rate)\n",
    "\n",
    "    print(\"Done generating all audio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c97682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_path = r\"C:\\Users\\japan\\datasets\\Speech\\metric-test\" #vivoice\n",
    "#generated_speech = r\"C:\\Users\\japan\\datasets\\Speech\\generated_speech\\cosyvoice2\"\n",
    "\n",
    "#real_path = r\"C:\\Users\\japan\\Downloads\\mcv-scripted-vi-v23.0\\cv-corpus-23.0-2025-09-05\\vi\\outputs\" #commonvoice vn\n",
    "\n",
    "real_path = r\"C:\\Users\\japan\\datasets\\Speech\\viet_bud500\"\n",
    "generated_speech = r\"C:\\Users\\japan\\datasets\\Speech\\generated_speech\\cosyvoice2_original\"\n",
    "\n",
    "generate_from_real_folder(real_path,generated_speech,cosyvoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40266aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230c5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosyvoice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
